---
title: "Stable Diffusion’s new model: SDXL beta"
description: "A newest, groundbreaking Stable Diffusion model is in open beta and we are taking it for a ride"
image: "https://imagedelivery.net/K11gkZF3xaVyYzFESMdWIQ/c6e5a413-2040-4898-9731-cfc1276a3900/full"
authorUsername: "Marek"
---

## Everyone can preview Stable Diffusion XL model

Recently Stable Diffusion has released to the public a new model, which is still in training, called Stable Diffusion XL (SDXL). I mean it is called that way for now, but in a final form it might be renamed. It is accessible to everyone through [DreamStudio](https://beta.dreamstudio.ai/generate), which is the official image generator of Stable Diffusion. Every user with a new account receives 25 credits for free to test the potential of a not yet finished LLM (large language model), with over [2.3 billion parameters.](https://twitter.com/EMostaque/status/1641795867740086272)

Stable Diffusion will release it to the public (will become an open source) as the training will be complete. But for now, let’s dive into it.

Oh, and all graphics in this article are created with the newest Stable Diffusion model, so let’s dive into SDXL beta.


### The UI

<Img src="https://imagedelivery.net/K11gkZF3xaVyYzFESMdWIQ/3459ed8a-3471-463c-e908-a0c45f5a7d00/full" alt="dream studio UI" />

First thing you notice as you login, for those who are not familiar with Dream Studio, is the friendly UI, so much clearer for those, who got used to Stable Diffusion webui.

We can choose some previous models, but we will focus naturally on the Stable Diffusion XL model beta.

There is added an edit but, which is not yet available, but I assume it will be some build in outpaint / inpaint feature.

Also a really cool feature which I think I haven’t seen anywhere else is the enhanced option (Adobe firefly has an option to choose an art style, not to enhance the existing one). It can help you create your image in one of 15 most popular art styles. Or just to enhance the style you are using right now.


Oh, and it’s trained for now only for square, 512 x 512 images, so keep that in mind as you will use it.


### Stable Diffusion XL model can generate text

As you are used to working with text to image, you won’t be surprised that you can have an option to add negative prompts. But you don't have to use as many of them as you used to have in previous Stable Diffusion models - it’s one of the milestones XL Stable Diffusion model reached.

And one of the greatest milestones StabilityAI achieved with the Stable Diffusion XL model is that it is** able to generate text**. Yeah, you read it right - you don’t have to edit your AI images out in order to have a text in them. I am really amazed as well.

<Img src="https://imagedelivery.net/K11gkZF3xaVyYzFESMdWIQ/2612602b-7752-4e86-875b-e5c4a7530100/full" alt="a man holding a sign that says you can write" />


### Better at human anatomy

<Img src="https://imagedelivery.net/K11gkZF3xaVyYzFESMdWIQ/bc91041e-52b1-452b-b701-4d89fdb39700/full" alt="woman in the forest doing warrior pose" />

With previous models, it didn't matter if we were talking about tools being used - Dall-e, Mid Journey or any other ones, AI struggles with anatomy. Extra limbs, fingers or just unnatural poses even became a meme across the internet. But jokes on you, as the Stable Diffusion XL model is dealing much, much better with all the motion tracking. I mean, you could have used ControlNet, but now you don’t need to.


### Improved quality of generations / aesthetic

<Img src="https://imagedelivery.net/K11gkZF3xaVyYzFESMdWIQ/3729ffd6-f30f-44b2-c52f-a109afe90a00/full" alt="a young woman dancing on a music festival" />

With the Stable Diffusion XL model you can generate more detailed images, more photorealistic ones. If I had to compare it to something, I would compare it to the quality of Mid Journey V5.  Doesn’t matter if you’re doing photorealistic images of humans, or designs of gorgeous cottages in some fairlands - Stable Diffusion XL model can help you with that. Oh, and it better understands the prompts provided.


## How can I use the Stable Diffusion XL model in real life?

Well, I would say that the only limitation out there is your imagination, but we already know that with text to image generative AI even that is not a problem. 

We don’t know the terms and conditions using the newest Stable Diffusion model, but we encourage you to enhance your creative process with AI. LLM are amazing tools, which can help you improve your work, make you work faster and more efficiently, not work at all :)

Here are some 3 ideas, how you can use Stable Diffusion in everyday life!


### Get inspired

Did you get a brief from a client, but you stuck on it? Use the newest Stable Diffusion model and type any amount of data you have, or whatever is on your mind and let the AI surprise you and unlock your potential with it’s suggestions.


### Fasten your work.

Do you have an idea to twist the concept a little bit? Maybe add some more objects into it, change lighting or the dominant color - use the newest Stable Diffusion model and in a couple of seconds see if adding more yellow or blue improves the overall feeling and if it does - go for it!


### Make your content unique

It doesn’t matter if you have to create a moodbook for your movie or brand for a meeting - what you always want it to be accurate (show your vision) and be unique - you are selling your own idea, your own story. And Stable Diffusion models are great in doing that. Test your idea with it and create the first draft of the solution and work on your own with the further ones. It’s that simple.


## Can I put Stable Diffusion into my workflow?

<Img src="https://imagedelivery.net/K11gkZF3xaVyYzFESMdWIQ/b0de41f8-34a4-4082-c588-ee7e8cfae400/full" alt="a man building a robot" />

Yeah, sure. I already mentioned a couple of use cases for including Stable Diffusion into your work. Stable Diffusion is an amazing open source tool, which means there are many incredible people worldwide who are contributing their time, skills and love for progress creating many tools and solutions with. Just look for them on [github](https://github.com/) or [huggingface](https://huggingface.co/).

And if you are facing a problem and you can’t find a tool to solve it, why not build one? We at lablab.ai are all about progress and innovation. We provide our community members sneak peeks into newest technologies through our blog posts and cutting edge solutions with our tutorials. But we also provide an environment where you can build on your own tools. Our AI hackathons are a great opportunity for AI lovers from all around the world to gather in one place and time and build amazing tools to solve the world's problems. And why not take your AI Hackathon project to the next level and build a startup around it? Sky’s the limit and it’s up to you if you want to be part of the AI revolution which will fix the world's problems!

Join our upcoming [Stable Diffusion Hackathon](https://lablab.ai/event/stable-diffusion-ai-hackathon) and build an amazing app using StabilityAI’s technology that will change the world we know. See all of the AI apps created with [Stable Diffusion](https://lablab.ai/apps/tech/stability-ai/stable-diffusion), [ChatGPT](https://lablab.ai/apps/tech/openai/chatgpt) and many, many other amazing technologies and get inspired by them.

Just join any [Hackathon artificial inteligence](https://lablab.ai/event) - it might be a life changing experience for you! Maybe an [OpenAI Hackathon](https://lablab.ai/event/openai-hackathon)?

Shape the world, as we know it. 

Build with Stable Diffusion. 

Join lablab.ai
